{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010afd81",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:18.108172Z",
     "iopub.status.busy": "2025-11-14T16:31:18.107827Z",
     "iopub.status.idle": "2025-11-14T16:31:38.769428Z",
     "shell.execute_reply": "2025-11-14T16:31:38.768816Z"
    },
    "papermill": {
     "duration": 20.670525,
     "end_time": "2025-11-14T16:31:38.770874",
     "exception": false,
     "start_time": "2025-11-14T16:31:18.100349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 16:31:23.530518: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763137883.738580      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763137883.795155      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7909eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.785629Z",
     "iopub.status.busy": "2025-11-14T16:31:38.784882Z",
     "iopub.status.idle": "2025-11-14T16:31:38.833095Z",
     "shell.execute_reply": "2025-11-14T16:31:38.832564Z"
    },
    "papermill": {
     "duration": 0.055746,
     "end_time": "2025-11-14T16:31:38.834201",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.778455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d844512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.846064Z",
     "iopub.status.busy": "2025-11-14T16:31:38.845513Z",
     "iopub.status.idle": "2025-11-14T16:31:38.909634Z",
     "shell.execute_reply": "2025-11-14T16:31:38.908899Z"
    },
    "papermill": {
     "duration": 0.071205,
     "end_time": "2025-11-14T16:31:38.910798",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.839593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "seed = 1234\n",
    "DATA_DIR = 'data'\n",
    "SEQ_LEN = 100\n",
    "VOCAB_SIZE = 5000\n",
    "EMB_DIM = 256\n",
    "ENC_HIDDEN_DIM = 512\n",
    "DEC_HIDDEN_DIM = 512\n",
    "DROPOUT = 0.3\n",
    "N_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 64\n",
    "# Output directories\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "LOG_DIR = 'runs'\n",
    "tokenizer_path = \"tknzer_dir\"\n",
    "special_tokens = [\"<pad>\", \"<st>\", \"<end>\", \"<unk>\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b99801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.923713Z",
     "iopub.status.busy": "2025-11-14T16:31:38.922982Z",
     "iopub.status.idle": "2025-11-14T16:31:38.931383Z",
     "shell.execute_reply": "2025-11-14T16:31:38.930620Z"
    },
    "papermill": {
     "duration": 0.016128,
     "end_time": "2025-11-14T16:31:38.932638",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.916510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a6236a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.944878Z",
     "iopub.status.busy": "2025-11-14T16:31:38.944639Z",
     "iopub.status.idle": "2025-11-14T16:31:38.948591Z",
     "shell.execute_reply": "2025-11-14T16:31:38.948042Z"
    },
    "papermill": {
     "duration": 0.011658,
     "end_time": "2025-11-14T16:31:38.949797",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.938139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696c708a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.961680Z",
     "iopub.status.busy": "2025-11-14T16:31:38.961500Z",
     "iopub.status.idle": "2025-11-14T16:31:38.965051Z",
     "shell.execute_reply": "2025-11-14T16:31:38.964330Z"
    },
    "papermill": {
     "duration": 0.010729,
     "end_time": "2025-11-14T16:31:38.966150",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.955421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_txt(txt_file):\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78a647b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.977915Z",
     "iopub.status.busy": "2025-11-14T16:31:38.977723Z",
     "iopub.status.idle": "2025-11-14T16:31:38.980515Z",
     "shell.execute_reply": "2025-11-14T16:31:38.980022Z"
    },
    "papermill": {
     "duration": 0.009824,
     "end_time": "2025-11-14T16:31:38.981529",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.971705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/iiith-assignment2-dataset/dataset/Pride_and_Prejudice-Jane_Austen.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e9cf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:38.992791Z",
     "iopub.status.busy": "2025-11-14T16:31:38.992597Z",
     "iopub.status.idle": "2025-11-14T16:31:38.996538Z",
     "shell.execute_reply": "2025-11-14T16:31:38.995909Z"
    },
    "papermill": {
     "duration": 0.010927,
     "end_time": "2025-11-14T16:31:38.997667",
     "exception": false,
     "start_time": "2025-11-14T16:31:38.986740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_text(text, lowercase = True):\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    # Unicode Normalization (e.g., converting fancy quotes to standard ones)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[\\*_`\\[\\]\\^{}]', '', text) # handle _word_ and *word*\n",
    "    text = re.sub(r'\\b(mr|mrs|ms|dr|st)\\.', r'\\1', text, flags=re.IGNORECASE) # handle mr. mrs. etc\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a08cccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.009115Z",
     "iopub.status.busy": "2025-11-14T16:31:39.008919Z",
     "iopub.status.idle": "2025-11-14T16:31:39.124053Z",
     "shell.execute_reply": "2025-11-14T16:31:39.123456Z"
    },
    "papermill": {
     "duration": 0.122314,
     "end_time": "2025-11-14T16:31:39.125380",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.003066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_dataset = normalize_text(load_txt(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6160cc8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.137515Z",
     "iopub.status.busy": "2025-11-14T16:31:39.137261Z",
     "iopub.status.idle": "2025-11-14T16:31:39.155435Z",
     "shell.execute_reply": "2025-11-14T16:31:39.154879Z"
    },
    "papermill": {
     "duration": 0.02543,
     "end_time": "2025-11-14T16:31:39.156450",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.131020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 702635)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(custom_dataset)), len(list(custom_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9f0e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.167966Z",
     "iopub.status.busy": "2025-11-14T16:31:39.167743Z",
     "iopub.status.idle": "2025-11-14T16:31:39.172174Z",
     "shell.execute_reply": "2025-11-14T16:31:39.171655Z"
    },
    "papermill": {
     "duration": 0.011326,
     "end_time": "2025-11-14T16:31:39.173081",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.161755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tokenizer(dataset, vocab_size, save_fldr, name = 'bpe'):\n",
    "    if os.path.exists(save_fldr):\n",
    "        save_path = os.path.join(save_fldr, 'tokenizer.json')\n",
    "        return Tokenizer.from_file(save_path)\n",
    "    if name == 'bpe':\n",
    "        tokenizer = Tokenizer(models.BPE())\n",
    "        tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "        trainer = BpeTrainer(vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "        tokenizer.train_from_iterator([dataset], trainer)\n",
    "        if save_fldr:\n",
    "            os.makedirs(save_fldr, exist_ok=True)\n",
    "            tokenizer.save(os.path.join(save_fldr, 'tokenizer.json'))\n",
    "            return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "200e5271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.184395Z",
     "iopub.status.busy": "2025-11-14T16:31:39.184200Z",
     "iopub.status.idle": "2025-11-14T16:31:39.558888Z",
     "shell.execute_reply": "2025-11-14T16:31:39.558141Z"
    },
    "papermill": {
     "duration": 0.381779,
     "end_time": "2025-11-14T16:31:39.560072",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.178293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bpe_tokenizer = get_tokenizer(custom_dataset, VOCAB_SIZE, tokenizer_path, 'bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19868992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.572002Z",
     "iopub.status.busy": "2025-11-14T16:31:39.571800Z",
     "iopub.status.idle": "2025-11-14T16:31:39.889368Z",
     "shell.execute_reply": "2025-11-14T16:31:39.888773Z"
    },
    "papermill": {
     "duration": 0.324943,
     "end_time": "2025-11-14T16:31:39.890622",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.565679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = bpe_tokenizer.encode(custom_dataset).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b346c1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.903489Z",
     "iopub.status.busy": "2025-11-14T16:31:39.903230Z",
     "iopub.status.idle": "2025-11-14T16:31:39.907696Z",
     "shell.execute_reply": "2025-11-14T16:31:39.906960Z"
    },
    "papermill": {
     "duration": 0.012519,
     "end_time": "2025-11-14T16:31:39.908899",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.896380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154018"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86dd1afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.920906Z",
     "iopub.status.busy": "2025-11-14T16:31:39.920354Z",
     "iopub.status.idle": "2025-11-14T16:31:39.924353Z",
     "shell.execute_reply": "2025-11-14T16:31:39.923692Z"
    },
    "papermill": {
     "duration": 0.011201,
     "end_time": "2025-11-14T16:31:39.925472",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.914271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(data, split, train_percent = 0.8):\n",
    "    n = len(data)\n",
    "    split_percent = train_percent\n",
    "    if split == \"train\":\n",
    "        return data[ : int((split_percent)*n)]\n",
    "    elif split == \"val\":\n",
    "        return data[int((split_percent)*n) : ]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d6ef4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.937125Z",
     "iopub.status.busy": "2025-11-14T16:31:39.936925Z",
     "iopub.status.idle": "2025-11-14T16:31:39.940555Z",
     "shell.execute_reply": "2025-11-14T16:31:39.940017Z"
    },
    "papermill": {
     "duration": 0.01076,
     "end_time": "2025-11-14T16:31:39.941626",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.930866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = get_data(tokenized_data,'train', train_percent = 0.8)\n",
    "val_data = get_data(tokenized_data,'val', train_percent = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd6863c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.954464Z",
     "iopub.status.busy": "2025-11-14T16:31:39.953859Z",
     "iopub.status.idle": "2025-11-14T16:31:39.958107Z",
     "shell.execute_reply": "2025-11-14T16:31:39.957561Z"
    },
    "papermill": {
     "duration": 0.011934,
     "end_time": "2025-11-14T16:31:39.959079",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.947145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57355086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.971761Z",
     "iopub.status.busy": "2025-11-14T16:31:39.971341Z",
     "iopub.status.idle": "2025-11-14T16:31:39.976964Z",
     "shell.execute_reply": "2025-11-14T16:31:39.976260Z"
    },
    "papermill": {
     "duration": 0.013285,
     "end_time": "2025-11-14T16:31:39.978021",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.964736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 15, 29, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Special token ids\n",
    "PAD_TOKEN = bpe_tokenizer.token_to_id('<pad>')\n",
    "ST_TOKEN = bpe_tokenizer.token_to_id('<st>')\n",
    "END_TOKEN = bpe_tokenizer.token_to_id('<end>')\n",
    "FULL_STOP = bpe_tokenizer.token_to_id('.')\n",
    "QUESTION_TOKEN = bpe_tokenizer.token_to_id('?')\n",
    "EXCLAMATION = bpe_tokenizer.token_to_id('!')\n",
    "special_ids = PAD_TOKEN, ST_TOKEN, END_TOKEN, FULL_STOP, QUESTION_TOKEN, EXCLAMATION\n",
    "special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d824fbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:39.990623Z",
     "iopub.status.busy": "2025-11-14T16:31:39.990398Z",
     "iopub.status.idle": "2025-11-14T16:31:39.999884Z",
     "shell.execute_reply": "2025-11-14T16:31:39.999178Z"
    },
    "papermill": {
     "duration": 0.01728,
     "end_time": "2025-11-14T16:31:40.001017",
     "exception": false,
     "start_time": "2025-11-14T16:31:39.983737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data, special_ids, seq_len):\n",
    "        super().__init__()\n",
    "        self.token_ids = data\n",
    "        self.seq_len = seq_len\n",
    "        self.pad, self.st, self.end, self.full_stop, self.quest, self.excl= special_ids\n",
    "        self.sentence_enders = {self.full_stop, self.quest, self.excl}\n",
    "        \n",
    "        self.inputs = []\n",
    "        self.decoder_inputs = []\n",
    "        self.decoder_targets = []\n",
    "        \n",
    "        \n",
    "        self.create_sequences()\n",
    "        \n",
    "    def create_sequences(self):\n",
    "        tokens = self.token_ids\n",
    "        n = len(tokens)\n",
    "        L = self.seq_len\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < n-1:\n",
    "            enc_seq = []\n",
    "            seq_end_idx = i \n",
    "            for j in range(L):\n",
    "                current_idx = i + j\n",
    "                if current_idx >= n:\n",
    "                    break\n",
    "                token = tokens[current_idx]\n",
    "                \n",
    "                enc_seq.append(token)\n",
    "                seq_end_idx = current_idx\n",
    "                \n",
    "                if token in self.sentence_enders:\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            if not enc_seq or len(enc_seq) < 2:\n",
    "                i = seq_end_idx + 1 # Move to the next token\n",
    "                continue\n",
    "\n",
    "            dec_target_seq = enc_seq[1:] + [self.end]\n",
    "            dec_input_seq = [self.st] + dec_target_seq[:-1]\n",
    "                \n",
    "            # Pad sequences if shorter\n",
    "            enc_seq_len = len(enc_seq)\n",
    "            enc_seq = enc_seq + [self.pad] * max(L - enc_seq_len, 0)\n",
    "            dec_input_seq = dec_input_seq + [self.pad] * max(L - enc_seq_len, 0)\n",
    "            dec_target_seq = dec_target_seq + [self.pad] * max(L - enc_seq_len, 0)\n",
    "\n",
    "            self.inputs.append(enc_seq)\n",
    "            self.decoder_inputs.append(dec_input_seq)\n",
    "            self.decoder_targets.append(dec_target_seq)\n",
    "            \n",
    "            i = seq_end_idx + 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.inputs[idx], dtype=torch.long), # encoder input 50 timesteps\n",
    "            torch.tensor(self.decoder_inputs[idx], dtype=torch.long), # decoder inputs shifter from target 50 steps\n",
    "            torch.tensor(self.decoder_targets[idx], dtype=torch.long) # decoder targets 50 steps\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "224303bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.013002Z",
     "iopub.status.busy": "2025-11-14T16:31:40.012801Z",
     "iopub.status.idle": "2025-11-14T16:31:40.060320Z",
     "shell.execute_reply": "2025-11-14T16:31:40.059777Z"
    },
    "papermill": {
     "duration": 0.054703,
     "end_time": "2025-11-14T16:31:40.061333",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.006630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpleDataset(train_data, special_ids, SEQ_LEN)\n",
    "val_dataset = SimpleDataset(val_data, special_ids, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c9ad308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.073650Z",
     "iopub.status.busy": "2025-11-14T16:31:40.073196Z",
     "iopub.status.idle": "2025-11-14T16:31:40.077625Z",
     "shell.execute_reply": "2025-11-14T16:31:40.076928Z"
    },
    "papermill": {
     "duration": 0.011863,
     "end_time": "2025-11-14T16:31:40.078756",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.066893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3667, 1225)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cddeb3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.091024Z",
     "iopub.status.busy": "2025-11-14T16:31:40.090640Z",
     "iopub.status.idle": "2025-11-14T16:31:40.134695Z",
     "shell.execute_reply": "2025-11-14T16:31:40.133885Z"
    },
    "papermill": {
     "duration": 0.0523,
     "end_time": "2025-11-14T16:31:40.136628",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.084328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 370, 2784,   13,  406,  876,   15,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]),\n",
       " tensor([   1, 2784,   13,  406,  876,   15,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]),\n",
       " tensor([2784,   13,  406,  876,   15,    2,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c67fe3c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.163604Z",
     "iopub.status.busy": "2025-11-14T16:31:40.162866Z",
     "iopub.status.idle": "2025-11-14T16:31:40.166908Z",
     "shell.execute_reply": "2025-11-14T16:31:40.166340Z"
    },
    "papermill": {
     "duration": 0.018034,
     "end_time": "2025-11-14T16:31:40.167957",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.149923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "350b9ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.180830Z",
     "iopub.status.busy": "2025-11-14T16:31:40.180527Z",
     "iopub.status.idle": "2025-11-14T16:31:40.188285Z",
     "shell.execute_reply": "2025-11-14T16:31:40.187496Z"
    },
    "papermill": {
     "duration": 0.020639,
     "end_time": "2025-11-14T16:31:40.194432",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.173793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# ENCODER\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.enc_hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len]\n",
    "        emb = self.embedding(x)  # [batch, seq_len, emb_dim]\n",
    "        outputs, (h, c) = self.lstm(emb)  # outputs: [batch, seq_len, 2*hidden]\n",
    "        return outputs, (h, c)\n",
    "\n",
    "# ATTENTION \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # We need to align the dimensions of encoder outputs and decoder hidden state\n",
    "        # enc_hidden_dim is for one direction, but encoder is bidirectional (2*)\n",
    "        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, dec_hidden, enc_outputs):\n",
    "        # dec_hidden: [batch, dec_hidden_dim] (from the *top layer* of decoder)\n",
    "        # enc_outputs: [batch, src_len, enc_hidden_dim * 2]\n",
    "        \n",
    "        batch_size = enc_outputs.shape[0]\n",
    "        src_len = enc_outputs.shape[1]\n",
    "        \n",
    "        # Repeat decoder hidden state src_len times to concatenate\n",
    "        # dec_hidden: [batch, src_len, dec_hidden_dim]\n",
    "        dec_hidden = dec_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        # energy: [batch, src_len, (enc_hidden * 2) + dec_hidden]\n",
    "        energy_input = torch.cat((dec_hidden, enc_outputs), dim = 2)\n",
    "        \n",
    "        # energy: [batch, src_len, dec_hidden_dim]\n",
    "        energy = torch.tanh(self.attn(energy_input))\n",
    "        \n",
    "        # v(energy): [batch, src_len, 1] -> [batch, src_len]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Return softmax'd weights\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, enc_hidden_dim, dec_hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dec_hidden_dim = dec_hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        \n",
    "        self.attention = Attention(enc_hidden_dim, dec_hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim + (enc_hidden_dim * 2),\n",
    "            hidden_size=dec_hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(dec_hidden_dim + (enc_hidden_dim * 2), vocab_size)\n",
    "    \n",
    "    def forward(self, dec_input, dec_hidden, enc_outputs):\n",
    "        # dec_input: [batch] -> current token IDs\n",
    "        # dec_hidden: (h, c) from previous step\n",
    "        # enc_outputs: [batch, src_len, 2*enc_hidden_dim]\n",
    "        \n",
    "        # dec_input [batch] -> [batch, 1]\n",
    "        dec_input = dec_input.unsqueeze(1)\n",
    "        \n",
    "        # emb: [batch, 1, emb_dim]\n",
    "        emb = self.embedding(dec_input)\n",
    "        \n",
    "       \n",
    "        a = self.attention(dec_hidden[0][-1], enc_outputs)\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        context = torch.bmm(a, enc_outputs)\n",
    "        \n",
    "        lstm_input = torch.cat([emb, context], dim=2)\n",
    "        output, dec_hidden = self.lstm(lstm_input, dec_hidden)\n",
    "        \n",
    "        output = output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "\n",
    "        concat_output = torch.cat([output, context], dim=1)\n",
    "        \n",
    "        logits = self.fc(concat_output)\n",
    "        \n",
    "        return logits, dec_hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        self.enc_num_layers = self.encoder.lstm.num_layers\n",
    "        self.enc_num_directions = 2 if self.encoder.lstm.bidirectional else 1\n",
    "        self.enc_hidden_dim = self.encoder.enc_hidden_dim\n",
    "        self.dec_hidden_dim = self.decoder.dec_hidden_dim\n",
    "        \n",
    "        self.fc_hidden = nn.Linear(self.enc_hidden_dim * self.enc_num_directions, self.dec_hidden_dim)\n",
    "        self.fc_cell = nn.Linear(self.enc_hidden_dim * self.enc_num_directions, self.dec_hidden_dim)\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        enc_outputs, (h, c) = self.encoder(src)\n",
    "        \n",
    "        h = h.view(self.enc_num_layers, self.enc_num_directions, batch_size, self.enc_hidden_dim)\n",
    "        c = c.view(self.enc_num_layers, self.enc_num_directions, batch_size, self.enc_hidden_dim)\n",
    "        \n",
    "        h_cat = torch.cat((h[:, 0, :, :], h[:, 1, :, :]), dim=2)\n",
    "        c_cat = torch.cat((c[:, 0, :, :], c[:, 1, :, :]), dim=2)\n",
    "        \n",
    "        dec_hidden = (torch.tanh(self.fc_hidden(h_cat)), \n",
    "                      torch.tanh(self.fc_cell(c_cat)))\n",
    "        \n",
    "        dec_input = trg[:, 0]\n",
    "        \n",
    "        # Loop from 0, store at t\n",
    "        for t in range(trg_len):\n",
    "            \n",
    "            # The decoder's forward pass now includes the attention mechanism\n",
    "            logits, dec_hidden = self.decoder(dec_input, dec_hidden, enc_outputs)\n",
    "            \n",
    "            outputs[:, t] = logits\n",
    "            \n",
    "            use_teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            if use_teacher_force:\n",
    "                if t < trg_len - 1:\n",
    "                    dec_input = trg[:, t+1]\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                top1 = logits.argmax(1)\n",
    "                dec_input = top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14f4f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.210709Z",
     "iopub.status.busy": "2025-11-14T16:31:40.210314Z",
     "iopub.status.idle": "2025-11-14T16:31:40.215770Z",
     "shell.execute_reply": "2025-11-14T16:31:40.215058Z"
    },
    "papermill": {
     "duration": 0.014469,
     "end_time": "2025-11-14T16:31:40.216900",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.202431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857ec6b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.230701Z",
     "iopub.status.busy": "2025-11-14T16:31:40.230094Z",
     "iopub.status.idle": "2025-11-14T16:31:40.729889Z",
     "shell.execute_reply": "2025-11-14T16:31:40.729244Z"
    },
    "papermill": {
     "duration": 0.507659,
     "end_time": "2025-11-14T16:31:40.731206",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.223547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE, EMB_DIM, ENC_HIDDEN_DIM, dropout=DROPOUT)\n",
    "decoder = Decoder(VOCAB_SIZE, EMB_DIM, ENC_HIDDEN_DIM, DEC_HIDDEN_DIM, dropout=DROPOUT)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b35129f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.744589Z",
     "iopub.status.busy": "2025-11-14T16:31:40.744173Z",
     "iopub.status.idle": "2025-11-14T16:31:40.748659Z",
     "shell.execute_reply": "2025-11-14T16:31:40.747957Z"
    },
    "papermill": {
     "duration": 0.012434,
     "end_time": "2025-11-14T16:31:40.749773",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.737339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5000, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5000, 256)\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (lstm): LSTM(1280, 512, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (fc): Linear(in_features=1536, out_features=5000, bias=True)\n",
       "  )\n",
       "  (fc_hidden): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc_cell): Linear(in_features=1024, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16284ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.762329Z",
     "iopub.status.busy": "2025-11-14T16:31:40.761837Z",
     "iopub.status.idle": "2025-11-14T16:31:40.767327Z",
     "shell.execute_reply": "2025-11-14T16:31:40.766641Z"
    },
    "papermill": {
     "duration": 0.0128,
     "end_time": "2025-11-14T16:31:40.768356",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.755556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_ckpt(model):\n",
    "    if os.path.exists(CHECKPOINT_DIR):\n",
    "        models = [os.path.join(CHECKPOINT_DIR,ckpt) for ckpt in os.listdir(CHECKPOINT_DIR)]\n",
    "        if len(models) > 0:\n",
    "            sorted_models = sorted(models, key=lambda x: x.split(\"_val\")[1].split('.pt')[0])\n",
    "            model.load_state_dict(torch.load(sorted_models[0], map_location=DEVICE))\n",
    "            print(f\"Loaded checkpoint from {sorted_models[0]}\")\n",
    "            best_loss = float(os.path.basename(sorted_models[0]).split(\"_val\")[1].split('.pt')[0])\n",
    "            last_epoch = int(os.path.basename(sorted_models[0]).split(\"_val\")[0].split('Epoch')[1])\n",
    "            return best_loss, last_epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24a53c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:40.781892Z",
     "iopub.status.busy": "2025-11-14T16:31:40.781708Z",
     "iopub.status.idle": "2025-11-14T16:31:45.406628Z",
     "shell.execute_reply": "2025-11-14T16:31:45.405810Z"
    },
    "papermill": {
     "duration": 4.633918,
     "end_time": "2025-11-14T16:31:45.408131",
     "exception": false,
     "start_time": "2025-11-14T16:31:40.774213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55f113f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.422109Z",
     "iopub.status.busy": "2025-11-14T16:31:45.421668Z",
     "iopub.status.idle": "2025-11-14T16:31:45.425311Z",
     "shell.execute_reply": "2025-11-14T16:31:45.424637Z"
    },
    "papermill": {
     "duration": 0.011518,
     "end_time": "2025-11-14T16:31:45.426350",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.414832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29d8ea94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.438940Z",
     "iopub.status.busy": "2025-11-14T16:31:45.438578Z",
     "iopub.status.idle": "2025-11-14T16:31:45.443417Z",
     "shell.execute_reply": "2025-11-14T16:31:45.442727Z"
    },
    "papermill": {
     "duration": 0.01232,
     "end_time": "2025-11-14T16:31:45.444593",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.432273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (src, dec_in, trg) in enumerate(iterator):\n",
    "        \n",
    "        src, dec_in, trg = src.to(DEVICE), dec_in.to(DEVICE), trg.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, dec_in)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b97f5668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.456971Z",
     "iopub.status.busy": "2025-11-14T16:31:45.456780Z",
     "iopub.status.idle": "2025-11-14T16:31:45.461296Z",
     "shell.execute_reply": "2025-11-14T16:31:45.460602Z"
    },
    "papermill": {
     "duration": 0.011916,
     "end_time": "2025-11-14T16:31:45.462297",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.450381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (src, dec_in, trg) in enumerate(iterator):\n",
    "            src, dec_in, trg = src.to(DEVICE), dec_in.to(DEVICE), trg.to(DEVICE)\n",
    "            output = model(src, dec_in)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9d92698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.475023Z",
     "iopub.status.busy": "2025-11-14T16:31:45.474819Z",
     "iopub.status.idle": "2025-11-14T16:31:45.483485Z",
     "shell.execute_reply": "2025-11-14T16:31:45.482782Z"
    },
    "papermill": {
     "duration": 0.016346,
     "end_time": "2025-11-14T16:31:45.484606",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.468260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_seq(model, texts, tokenizer, seq_len, special_ids, gen_len=100):\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    pad, st, end, full_stop, quest, excl= special_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # prepare encoder input\n",
    "            text = normalize_text(text)\n",
    "            ids = tokenizer.encode(text).ids\n",
    "            if len(ids) < seq_len:\n",
    "                ids = ids + [pad] * (seq_len - len(ids))\n",
    "            else:\n",
    "                print(\"Warning: More than seq length -- considering first 50 tokens:\")\n",
    "                ids = ids[:seq_len]\n",
    "\n",
    "            src = torch.tensor([ids], dtype=torch.long, device=DEVICE)\n",
    "            # print(src.shape)\n",
    "            # print(src)\n",
    "\n",
    "            # start decoder with only the start token (length = 1)\n",
    "            dec_in = torch.tensor([[st]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "            generated = []\n",
    "            for step in range(gen_len):\n",
    "                out = model(src, dec_in)          # [1, cur_dec_len, vocab_size]\n",
    "                next_token = int(out[0, -1].argmax().cpu().item())  # last timestep prediction\n",
    "                generated.append(next_token)\n",
    "                \n",
    "                # if next_token == end:\n",
    "                #     break\n",
    "\n",
    "                \n",
    "\n",
    "                # append predicted token to decoder input for next step\n",
    "                dec_in = torch.cat(\n",
    "                    [dec_in, torch.tensor([[next_token]], dtype=torch.long, device=DEVICE)],\n",
    "                    dim=1\n",
    "                )\n",
    "            # convert ids -> tokens\n",
    "            # print(\"Out Tokens\", generated)\n",
    "            tokens = [tokenizer.id_to_token(tid) for tid in generated]\n",
    "            samples.append((text, tokens))\n",
    "\n",
    "    print(\"=== Sample generations ===\")\n",
    "    for idx, (inp, toks) in enumerate(samples, 1):\n",
    "        print(f\"[{idx}] INPUT : {inp}\")\n",
    "        print(f\"OUTPUT: {' '.join(toks)}\")\n",
    "    print(\"======================================================\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b54df3a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.497032Z",
     "iopub.status.busy": "2025-11-14T16:31:45.496825Z",
     "iopub.status.idle": "2025-11-14T16:31:45.501362Z",
     "shell.execute_reply": "2025-11-14T16:31:45.500673Z"
    },
    "papermill": {
     "duration": 0.01214,
     "end_time": "2025-11-14T16:31:45.502509",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.490369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61a608e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.514861Z",
     "iopub.status.busy": "2025-11-14T16:31:45.514643Z",
     "iopub.status.idle": "2025-11-14T16:31:45.518999Z",
     "shell.execute_reply": "2025-11-14T16:31:45.518472Z"
    },
    "papermill": {
     "duration": 0.011692,
     "end_time": "2025-11-14T16:31:45.519990",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.508298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIt is quite an interesting format, if you don't like the opening you are reading,\\nthen you can skip and go to the next book opening. If the opening does capture your attention\\nyou can click at the bottom to reveal the title and author. It reminds me of blind date books \\nwhere bookstores will wrap a random book up in paper (to prevent the title and author from being seen)\\nand will write brief descriptions about it.\\n\\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text from internet\n",
    "\"\"\"If I could have ceased what pendulums swung, or wheels turned, \n",
    "or water clocks emptied, then, in order to keep the Fates from marching in time,\n",
    "I would have, for though it is what a boy naturally wishes when he fears change will \n",
    "come upon what he loves and take it away, a man remembers it, too, and in his heart \n",
    "wishes the same when all around him he feels only loss, loss that has been his \n",
    "companion for some time, and promises to remain at his side.\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "It is quite an interesting format, if you don't like the opening you are reading,\n",
    "then you can skip and go to the next book opening. If the opening does capture your attention\n",
    "you can click at the bottom to reveal the title and author. It reminds me of blind date books \n",
    "where bookstores will wrap a random book up in paper (to prevent the title and author from being seen)\n",
    "and will write brief descriptions about it.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f53635b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.532759Z",
     "iopub.status.busy": "2025-11-14T16:31:45.532218Z",
     "iopub.status.idle": "2025-11-14T16:31:45.535432Z",
     "shell.execute_reply": "2025-11-14T16:31:45.534744Z"
    },
    "papermill": {
     "duration": 0.010784,
     "end_time": "2025-11-14T16:31:45.536578",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.525794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CUSTOM_TEXTS = [\n",
    "                \"If I could have ceased\",\n",
    "                \"It is quite an interesting format, if you\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "800f6713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.549535Z",
     "iopub.status.busy": "2025-11-14T16:31:45.548992Z",
     "iopub.status.idle": "2025-11-14T16:31:45.555909Z",
     "shell.execute_reply": "2025-11-14T16:31:45.555322Z"
    },
    "papermill": {
     "duration": 0.014473,
     "end_time": "2025-11-14T16:31:45.556973",
     "exception": false,
     "start_time": "2025-11-14T16:31:45.542500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_lm(predict_while_train = True, resume_ckpt = True):\n",
    "    best_valid_loss = float('inf')\n",
    "    last_epoch = 0\n",
    "    if resume_ckpt:\n",
    "        if os.listdir(CHECKPOINT_DIR):\n",
    "            best_valid_loss, last_epoch = load_ckpt(model)\n",
    "    \n",
    "    for epoch in tqdm(range(N_EPOCHS), desc=\"Started Training\"):\n",
    "        epoch += last_epoch\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if predict_while_train:\n",
    "            if epoch%5 == 0:\n",
    "                generate_seq(model, CUSTOM_TEXTS, bpe_tokenizer, SEQ_LEN, special_ids, gen_len=50)\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        valid_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        epoch_mins = int((end_time - start_time) / 60)\n",
    "        epoch_secs = int((end_time - start_time) - (epoch_mins * 60))\n",
    "\n",
    "        # Save checkpoint if validation loss has improved\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f'Epoch{epoch}_val{valid_loss}.pt'))\n",
    "            print(f\"Checkpoint saved: New best validation loss {best_valid_loss:.3f}\")\n",
    "\n",
    "        # TensorBoard logging\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Perplexity/train', math.exp(train_loss), epoch)\n",
    "        writer.add_scalar('Loss/validation', valid_loss, epoch)\n",
    "        writer.add_scalar('Perplexity/validation', math.exp(valid_loss), epoch)\n",
    "        writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c64e778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T16:31:45.570410Z",
     "iopub.status.busy": "2025-11-14T16:31:45.570155Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-11-14T16:31:45.563084",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra attra\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: attra attra attra attra attra attra attra because attra attra attra attra attra attra attra attra fa attra attra attra attra attra attra attra attra fa attra attra attra attra attra attra attra attra fa attra attra attra attra attra attra attra attra fa attra attra attra attra attra attra\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   0%|          | 1/200 [01:05<3:36:57, 65.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 6.211\n",
      "Epoch: 01 | Time: 1m 5s\n",
      "\tTrain Loss: 6.408 | Train PPL: 606.449\n",
      "\t Val. Loss: 6.211 |  Val. PPL: 498.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   1%|          | 2/200 [02:08<3:30:27, 63.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 5.949\n",
      "Epoch: 02 | Time: 1m 2s\n",
      "\tTrain Loss: 5.862 | Train PPL: 351.543\n",
      "\t Val. Loss: 5.949 |  Val. PPL: 383.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   2%|         | 3/200 [03:10<3:27:42, 63.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 5.653\n",
      "Epoch: 03 | Time: 1m 2s\n",
      "\tTrain Loss: 5.515 | Train PPL: 248.295\n",
      "\t Val. Loss: 5.653 |  Val. PPL: 285.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   2%|         | 4/200 [04:13<3:25:49, 63.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 5.253\n",
      "Epoch: 04 | Time: 1m 2s\n",
      "\tTrain Loss: 5.072 | Train PPL: 159.571\n",
      "\t Val. Loss: 5.253 |  Val. PPL: 191.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   2%|         | 5/200 [05:15<3:24:18, 62.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 4.812\n",
      "Epoch: 05 | Time: 1m 2s\n",
      "\tTrain Loss: 4.469 | Train PPL:  87.245\n",
      "\t Val. Loss: 4.812 |  Val. PPL: 122.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: <end> could have have l ! <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: <end> by an rou t , if you must <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   3%|         | 6/200 [06:20<3:25:23, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 4.427\n",
      "Epoch: 06 | Time: 1m 4s\n",
      "\tTrain Loss: 3.940 | Train PPL:  51.441\n",
      "\t Val. Loss: 4.427 |  Val. PPL:  83.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   4%|         | 7/200 [07:23<3:23:17, 63.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 4.175\n",
      "Epoch: 07 | Time: 1m 2s\n",
      "\tTrain Loss: 3.352 | Train PPL:  28.571\n",
      "\t Val. Loss: 4.175 |  Val. PPL:  65.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   4%|         | 8/200 [08:25<3:21:36, 63.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.857\n",
      "Epoch: 08 | Time: 1m 2s\n",
      "\tTrain Loss: 2.913 | Train PPL:  18.414\n",
      "\t Val. Loss: 3.857 |  Val. PPL:  47.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   4%|         | 9/200 [09:28<3:20:08, 62.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.710\n",
      "Epoch: 09 | Time: 1m 2s\n",
      "\tTrain Loss: 2.520 | Train PPL:  12.423\n",
      "\t Val. Loss: 3.710 |  Val. PPL:  40.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   5%|         | 10/200 [10:30<3:18:48, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.634\n",
      "Epoch: 10 | Time: 1m 2s\n",
      "\tTrain Loss: 2.251 | Train PPL:   9.494\n",
      "\t Val. Loss: 3.634 |  Val. PPL:  37.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: <end> could have provo <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: <end> quite an amiable niece , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   6%|         | 11/200 [11:35<3:19:41, 63.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.519\n",
      "Epoch: 11 | Time: 1m 4s\n",
      "\tTrain Loss: 2.043 | Train PPL:   7.717\n",
      "\t Val. Loss: 3.519 |  Val. PPL:  33.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   6%|         | 12/200 [12:38<3:17:49, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.243\n",
      "Epoch: 12 | Time: 1m 2s\n",
      "\tTrain Loss: 1.792 | Train PPL:   6.002\n",
      "\t Val. Loss: 3.243 |  Val. PPL:  25.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   6%|         | 13/200 [13:40<3:16:03, 62.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 1m 2s\n",
      "\tTrain Loss: 1.595 | Train PPL:   4.930\n",
      "\t Val. Loss: 3.784 |  Val. PPL:  44.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   7%|         | 14/200 [14:43<3:14:44, 62.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 3.006\n",
      "Epoch: 14 | Time: 1m 2s\n",
      "\tTrain Loss: 1.422 | Train PPL:   4.146\n",
      "\t Val. Loss: 3.006 |  Val. PPL:  20.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   8%|         | 15/200 [15:45<3:13:15, 62.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 1m 2s\n",
      "\tTrain Loss: 1.300 | Train PPL:   3.668\n",
      "\t Val. Loss: 3.270 |  Val. PPL:  26.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: stretch could have died <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: <end> quite an greatest , , you you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   8%|         | 16/200 [16:50<3:14:07, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.981\n",
      "Epoch: 16 | Time: 1m 4s\n",
      "\tTrain Loss: 1.168 | Train PPL:   3.217\n",
      "\t Val. Loss: 2.981 |  Val. PPL:  19.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   8%|         | 17/200 [17:53<3:12:29, 63.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.835\n",
      "Epoch: 17 | Time: 1m 2s\n",
      "\tTrain Loss: 1.059 | Train PPL:   2.885\n",
      "\t Val. Loss: 2.835 |  Val. PPL:  17.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:   9%|         | 18/200 [18:55<3:10:53, 62.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.740\n",
      "Epoch: 18 | Time: 1m 2s\n",
      "\tTrain Loss: 0.883 | Train PPL:   2.419\n",
      "\t Val. Loss: 2.740 |  Val. PPL:  15.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  10%|         | 19/200 [19:58<3:09:31, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.688\n",
      "Epoch: 19 | Time: 1m 2s\n",
      "\tTrain Loss: 0.812 | Train PPL:   2.251\n",
      "\t Val. Loss: 2.688 |  Val. PPL:  14.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  10%|         | 20/200 [21:00<3:08:11, 62.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.688\n",
      "Epoch: 20 | Time: 1m 2s\n",
      "\tTrain Loss: 0.814 | Train PPL:   2.256\n",
      "\t Val. Loss: 2.688 |  Val. PPL:  14.702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: afforded could have cast your guard <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: afforded quite an rou , , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  10%|         | 21/200 [22:05<3:08:46, 63.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 1m 4s\n",
      "\tTrain Loss: 0.725 | Train PPL:   2.065\n",
      "\t Val. Loss: 2.715 |  Val. PPL:  15.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  11%|         | 22/200 [23:07<3:07:03, 63.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.543\n",
      "Epoch: 22 | Time: 1m 2s\n",
      "\tTrain Loss: 0.677 | Train PPL:   1.969\n",
      "\t Val. Loss: 2.543 |  Val. PPL:  12.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  12%|        | 23/200 [24:10<3:05:27, 62.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 1m 2s\n",
      "\tTrain Loss: 0.575 | Train PPL:   1.778\n",
      "\t Val. Loss: 2.592 |  Val. PPL:  13.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  12%|        | 24/200 [25:12<3:04:01, 62.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 1m 2s\n",
      "\tTrain Loss: 0.578 | Train PPL:   1.783\n",
      "\t Val. Loss: 2.611 |  Val. PPL:  13.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  12%|        | 25/200 [26:15<3:02:44, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 1m 2s\n",
      "\tTrain Loss: 0.502 | Train PPL:   1.652\n",
      "\t Val. Loss: 2.581 |  Val. PPL:  13.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: overlooked could have liberal <end> <end> <end> philosophy <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: overlooked quite an interesting meanwhile , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  13%|        | 26/200 [27:19<3:03:33, 63.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.518\n",
      "Epoch: 26 | Time: 1m 4s\n",
      "\tTrain Loss: 0.548 | Train PPL:   1.729\n",
      "\t Val. Loss: 2.518 |  Val. PPL:  12.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  14%|        | 27/200 [28:22<3:01:44, 63.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 1m 2s\n",
      "\tTrain Loss: 0.456 | Train PPL:   1.577\n",
      "\t Val. Loss: 2.584 |  Val. PPL:  13.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  14%|        | 28/200 [29:24<3:00:08, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 1m 2s\n",
      "\tTrain Loss: 0.439 | Train PPL:   1.552\n",
      "\t Val. Loss: 2.709 |  Val. PPL:  15.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  14%|        | 29/200 [30:27<2:58:49, 62.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.443\n",
      "Epoch: 29 | Time: 1m 2s\n",
      "\tTrain Loss: 0.508 | Train PPL:   1.662\n",
      "\t Val. Loss: 2.443 |  Val. PPL:  11.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  15%|        | 30/200 [31:29<2:57:27, 62.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 1m 2s\n",
      "\tTrain Loss: 0.421 | Train PPL:   1.523\n",
      "\t Val. Loss: 2.484 |  Val. PPL:  11.990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: lord could have wood nove <end> journey journey <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: lord quite an rou ously , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  16%|        | 31/200 [32:34<2:58:14, 63.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.422\n",
      "Epoch: 31 | Time: 1m 4s\n",
      "\tTrain Loss: 0.433 | Train PPL:   1.542\n",
      "\t Val. Loss: 2.422 |  Val. PPL:  11.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  16%|        | 32/200 [33:36<2:56:27, 63.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Time: 1m 2s\n",
      "\tTrain Loss: 0.414 | Train PPL:   1.513\n",
      "\t Val. Loss: 2.446 |  Val. PPL:  11.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  16%|        | 33/200 [34:39<2:54:53, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Time: 1m 2s\n",
      "\tTrain Loss: 0.341 | Train PPL:   1.406\n",
      "\t Val. Loss: 2.486 |  Val. PPL:  12.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  17%|        | 34/200 [35:41<2:53:34, 62.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.417\n",
      "Epoch: 34 | Time: 1m 2s\n",
      "\tTrain Loss: 0.355 | Train PPL:   1.426\n",
      "\t Val. Loss: 2.417 |  Val. PPL:  11.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  18%|        | 35/200 [36:44<2:52:17, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Time: 1m 2s\n",
      "\tTrain Loss: 0.321 | Train PPL:   1.379\n",
      "\t Val. Loss: 2.661 |  Val. PPL:  14.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: missed could have mary <end> <end> <end> shaken <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: missed quite an strange concern , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  18%|        | 36/200 [37:48<2:52:52, 63.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Time: 1m 4s\n",
      "\tTrain Loss: 0.386 | Train PPL:   1.471\n",
      "\t Val. Loss: 2.442 |  Val. PPL:  11.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  18%|        | 37/200 [38:51<2:51:14, 63.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.376\n",
      "Epoch: 37 | Time: 1m 2s\n",
      "\tTrain Loss: 0.339 | Train PPL:   1.404\n",
      "\t Val. Loss: 2.376 |  Val. PPL:  10.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  19%|        | 38/200 [39:53<2:49:47, 62.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.369\n",
      "Epoch: 38 | Time: 1m 2s\n",
      "\tTrain Loss: 0.299 | Train PPL:   1.348\n",
      "\t Val. Loss: 2.369 |  Val. PPL:  10.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  20%|        | 39/200 [40:56<2:48:22, 62.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Time: 1m 2s\n",
      "\tTrain Loss: 0.317 | Train PPL:   1.373\n",
      "\t Val. Loss: 2.408 |  Val. PPL:  11.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  20%|        | 40/200 [41:58<2:47:00, 62.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Time: 1m 2s\n",
      "\tTrain Loss: 0.316 | Train PPL:   1.372\n",
      "\t Val. Loss: 2.485 |  Val. PPL:  12.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: tranqu could have shut <end> <end> <end> <end> ption <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: tranqu quite an interesting niece , if you <end> <end> <end> <end> <end> <end> <end> <end> outh <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  20%|        | 41/200 [43:03<2:47:30, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Time: 1m 4s\n",
      "\tTrain Loss: 0.312 | Train PPL:   1.366\n",
      "\t Val. Loss: 2.411 |  Val. PPL:  11.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  21%|        | 42/200 [44:05<2:45:55, 63.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.366\n",
      "Epoch: 42 | Time: 1m 2s\n",
      "\tTrain Loss: 0.320 | Train PPL:   1.377\n",
      "\t Val. Loss: 2.366 |  Val. PPL:  10.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  22%|       | 43/200 [45:08<2:44:26, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Time: 1m 2s\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 2.586 |  Val. PPL:  13.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  22%|       | 44/200 [46:10<2:43:04, 62.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Time: 1m 2s\n",
      "\tTrain Loss: 0.382 | Train PPL:   1.465\n",
      "\t Val. Loss: 2.420 |  Val. PPL:  11.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  22%|       | 45/200 [47:13<2:41:46, 62.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Time: 1m 2s\n",
      "\tTrain Loss: 0.352 | Train PPL:   1.422\n",
      "\t Val. Loss: 2.420 |  Val. PPL:  11.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: bu could have observed ased <end> <end> <end> bu if if <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: bu quite an griev ager , if you <end> <end> <end> <end> bu omy amusing <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  23%|       | 46/200 [48:17<2:42:15, 63.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Time: 1m 4s\n",
      "\tTrain Loss: 0.375 | Train PPL:   1.455\n",
      "\t Val. Loss: 2.486 |  Val. PPL:  12.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  24%|       | 47/200 [49:20<2:40:35, 62.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Time: 1m 2s\n",
      "\tTrain Loss: 0.340 | Train PPL:   1.405\n",
      "\t Val. Loss: 2.478 |  Val. PPL:  11.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  24%|       | 48/200 [50:22<2:39:06, 62.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Time: 1m 2s\n",
      "\tTrain Loss: 0.342 | Train PPL:   1.408\n",
      "\t Val. Loss: 2.464 |  Val. PPL:  11.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  24%|       | 49/200 [51:25<2:38:03, 62.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.266\n",
      "Epoch: 49 | Time: 1m 2s\n",
      "\tTrain Loss: 0.229 | Train PPL:   1.257\n",
      "\t Val. Loss: 2.266 |  Val. PPL:   9.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  25%|       | 50/200 [52:27<2:36:50, 62.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.249\n",
      "Epoch: 50 | Time: 1m 2s\n",
      "\tTrain Loss: 0.156 | Train PPL:   1.169\n",
      "\t Val. Loss: 2.249 |  Val. PPL:   9.482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have keep <end> <end> <end> <end> sex ? <end> dependence <end> dependence feels <end> omy six son <end> <end> omy six son <end> <end> <end> omy six son <end> <end> <end> omy six <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy six <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting connection , if you <end> <end> <end> <end> feels <end> feels . <end> <end> <end> <end> <end> omy six son . <end> <end> <end> <end> omy six son . <end> <end> <end> <end> omy six <end> <end> omy <end> <end> omy <end> <end> <end> omy <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  26%|       | 51/200 [53:32<2:37:21, 63.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.211\n",
      "Epoch: 51 | Time: 1m 4s\n",
      "\tTrain Loss: 0.119 | Train PPL:   1.126\n",
      "\t Val. Loss: 2.211 |  Val. PPL:   9.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  26%|       | 52/200 [54:35<2:35:39, 63.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | Time: 1m 2s\n",
      "\tTrain Loss: 0.102 | Train PPL:   1.107\n",
      "\t Val. Loss: 2.222 |  Val. PPL:   9.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  26%|       | 53/200 [55:37<2:34:08, 62.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | Time: 1m 2s\n",
      "\tTrain Loss: 0.096 | Train PPL:   1.101\n",
      "\t Val. Loss: 2.226 |  Val. PPL:   9.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  27%|       | 54/200 [56:40<2:32:52, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.169\n",
      "Epoch: 54 | Time: 1m 2s\n",
      "\tTrain Loss: 0.075 | Train PPL:   1.078\n",
      "\t Val. Loss: 2.169 |  Val. PPL:   8.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  28%|       | 55/200 [57:42<2:31:43, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.121\n",
      "Epoch: 55 | Time: 1m 2s\n",
      "\tTrain Loss: 0.080 | Train PPL:   1.083\n",
      "\t Val. Loss: 2.121 |  Val. PPL:   8.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: bu could have abilities <end> <end> <end> <end> <end> dependence . <end> <end> omy six son . <end> <end> omy six omy ery <end> <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> omy <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: bu quite an rou tone , if you <end> <end> <end> <end> <end> <end> <end> <end> dependence . <end> <end> omy . <end> <end> omy <end> <end> omy <end> <end> omy <end> <end> <end> omy <end> <end> <end> omy <end> <end> <end> omy <end> <end> <end> omy <end> <end> omy\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  28%|       | 56/200 [58:47<2:32:04, 63.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | Time: 1m 4s\n",
      "\tTrain Loss: 0.063 | Train PPL:   1.065\n",
      "\t Val. Loss: 2.199 |  Val. PPL:   9.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  28%|       | 57/200 [59:50<2:30:20, 63.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 | Time: 1m 2s\n",
      "\tTrain Loss: 0.064 | Train PPL:   1.066\n",
      "\t Val. Loss: 2.228 |  Val. PPL:   9.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  29%|       | 58/200 [1:00:52<2:28:55, 62.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.121\n",
      "Epoch: 58 | Time: 1m 2s\n",
      "\tTrain Loss: 0.059 | Train PPL:   1.061\n",
      "\t Val. Loss: 2.121 |  Val. PPL:   8.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  30%|       | 59/200 [1:01:55<2:27:31, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | Time: 1m 2s\n",
      "\tTrain Loss: 0.062 | Train PPL:   1.064\n",
      "\t Val. Loss: 2.145 |  Val. PPL:   8.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  30%|       | 60/200 [1:02:57<2:26:14, 62.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Time: 1m 2s\n",
      "\tTrain Loss: 0.052 | Train PPL:   1.054\n",
      "\t Val. Loss: 2.134 |  Val. PPL:   8.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have ? <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: bu quite an rou ug , if you <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  30%|       | 61/200 [1:04:02<2:26:39, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 | Time: 1m 4s\n",
      "\tTrain Loss: 0.060 | Train PPL:   1.062\n",
      "\t Val. Loss: 2.159 |  Val. PPL:   8.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  31%|       | 62/200 [1:05:04<2:25:00, 63.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | Time: 1m 2s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 2.136 |  Val. PPL:   8.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  32%|      | 63/200 [1:06:07<2:23:33, 62.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 | Time: 1m 2s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 2.126 |  Val. PPL:   8.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  32%|      | 64/200 [1:07:09<2:22:12, 62.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 | Time: 1m 2s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 2.177 |  Val. PPL:   8.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  32%|      | 65/200 [1:08:12<2:20:58, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 | Time: 1m 2s\n",
      "\tTrain Loss: 0.049 | Train PPL:   1.050\n",
      "\t Val. Loss: 2.133 |  Val. PPL:   8.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have discovered <end> perfect nature ached acutely :// ached acutely . <end> <end> <end> <end> <end> omy . <end> <end> omy . <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting laughing , if you need <end> <end> <end> acutely & omy . <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  33%|      | 66/200 [1:09:16<2:21:23, 63.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.100\n",
      "Epoch: 66 | Time: 1m 4s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 2.100 |  Val. PPL:   8.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  34%|      | 67/200 [1:10:19<2:19:44, 63.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | Time: 1m 2s\n",
      "\tTrain Loss: 0.033 | Train PPL:   1.034\n",
      "\t Val. Loss: 2.132 |  Val. PPL:   8.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  34%|      | 68/200 [1:11:21<2:18:20, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | Time: 1m 2s\n",
      "\tTrain Loss: 0.031 | Train PPL:   1.031\n",
      "\t Val. Loss: 2.104 |  Val. PPL:   8.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  34%|      | 69/200 [1:12:24<2:17:03, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | Time: 1m 2s\n",
      "\tTrain Loss: 0.034 | Train PPL:   1.035\n",
      "\t Val. Loss: 2.102 |  Val. PPL:   8.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  35%|      | 70/200 [1:13:26<2:15:50, 62.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | Time: 1m 2s\n",
      "\tTrain Loss: 0.030 | Train PPL:   1.031\n",
      "\t Val. Loss: 2.159 |  Val. PPL:   8.665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have discovered <end> perfect nature ached acutely :// ached acutely :// acutely . <end> <end> <end> omy :// <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting laughing , if you need <end> <end> <end> acutely . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> omy . <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  36%|      | 71/200 [1:14:31<2:16:10, 63.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.097\n",
      "Epoch: 71 | Time: 1m 4s\n",
      "\tTrain Loss: 0.033 | Train PPL:   1.034\n",
      "\t Val. Loss: 2.097 |  Val. PPL:   8.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  36%|      | 72/200 [1:15:34<2:14:32, 63.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 | Time: 1m 2s\n",
      "\tTrain Loss: 0.028 | Train PPL:   1.028\n",
      "\t Val. Loss: 2.120 |  Val. PPL:   8.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  36%|      | 73/200 [1:16:36<2:13:09, 62.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 | Time: 1m 2s\n",
      "\tTrain Loss: 0.029 | Train PPL:   1.029\n",
      "\t Val. Loss: 2.132 |  Val. PPL:   8.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  37%|      | 74/200 [1:17:39<2:11:51, 62.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 | Time: 1m 2s\n",
      "\tTrain Loss: 0.029 | Train PPL:   1.029\n",
      "\t Val. Loss: 2.182 |  Val. PPL:   8.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  38%|      | 75/200 [1:18:41<2:10:37, 62.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Time: 1m 2s\n",
      "\tTrain Loss: 0.023 | Train PPL:   1.023\n",
      "\t Val. Loss: 2.098 |  Val. PPL:   8.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have discovered <end> <end> <end> <end> acutely ached :// feels . <end> acutely . <end> <end> omy :// <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting laughing , if you need <end> <end> <end> acutely . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> omy . <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  38%|      | 76/200 [1:19:46<2:10:49, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 | Time: 1m 4s\n",
      "\tTrain Loss: 0.025 | Train PPL:   1.025\n",
      "\t Val. Loss: 2.145 |  Val. PPL:   8.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  38%|      | 77/200 [1:20:48<2:09:13, 63.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | Time: 1m 2s\n",
      "\tTrain Loss: 0.023 | Train PPL:   1.023\n",
      "\t Val. Loss: 2.104 |  Val. PPL:   8.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  39%|      | 78/200 [1:21:51<2:07:52, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 | Time: 1m 2s\n",
      "\tTrain Loss: 0.027 | Train PPL:   1.028\n",
      "\t Val. Loss: 2.125 |  Val. PPL:   8.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  40%|      | 79/200 [1:22:53<2:06:35, 62.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 | Time: 1m 2s\n",
      "\tTrain Loss: 0.032 | Train PPL:   1.033\n",
      "\t Val. Loss: 2.108 |  Val. PPL:   8.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  40%|      | 80/200 [1:23:56<2:05:31, 62.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: New best validation loss 2.074\n",
      "Epoch: 80 | Time: 1m 2s\n",
      "\tTrain Loss: 0.027 | Train PPL:   1.027\n",
      "\t Val. Loss: 2.074 |  Val. PPL:   7.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have discovered <end> <end> <end> <end> acutely ached :// feels . <end> <end> omy :// <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> omy .\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting delightful , if you need <end> <end> <end> acutely . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  40%|      | 81/200 [1:25:01<2:05:42, 63.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 | Time: 1m 4s\n",
      "\tTrain Loss: 0.031 | Train PPL:   1.031\n",
      "\t Val. Loss: 2.146 |  Val. PPL:   8.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  41%|      | 82/200 [1:26:04<2:04:11, 63.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | Time: 1m 2s\n",
      "\tTrain Loss: 0.028 | Train PPL:   1.028\n",
      "\t Val. Loss: 2.099 |  Val. PPL:   8.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  42%|     | 83/200 [1:27:06<2:02:49, 62.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 | Time: 1m 2s\n",
      "\tTrain Loss: 0.037 | Train PPL:   1.038\n",
      "\t Val. Loss: 2.159 |  Val. PPL:   8.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  42%|     | 84/200 [1:28:09<2:01:31, 62.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 | Time: 1m 2s\n",
      "\tTrain Loss: 0.029 | Train PPL:   1.030\n",
      "\t Val. Loss: 2.136 |  Val. PPL:   8.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  42%|     | 85/200 [1:29:11<2:00:18, 62.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 | Time: 1m 2s\n",
      "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
      "\t Val. Loss: 2.149 |  Val. PPL:   8.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample generations ===\n",
      "[1] INPUT : if i could have ceased\n",
      "OUTPUT: collected could have discovered <end> <end> <end> <end> acutely ached :// feels . <end> <end> omy :// <end> omy . <end> <end> <end> omy . <end> <end> <end> omy . <end> <end> <end> <end> omy . <end> <end> <end> <end> omy . <end> <end> <end> <end> omy . <end> <end>\n",
      "[2] INPUT : it is quite an interesting format, if you\n",
      "OUTPUT: collected quite an interesting delightful , if you need <end> <end> <end> acutely . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> omy . <end> <end> <end> <end> <end> <end> <end>\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Started Training:  43%|     | 86/200 [1:30:16<2:00:27, 63.40s/it]"
     ]
    }
   ],
   "source": [
    "run_lm(predict_while_train = True, resume_ckpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887e7cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_seq(model, [\"Hi, introduce yourself\"], bpe_tokenizer, SEQ_LEN, special_ids, gen_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ef9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8736113,
     "sourceId": 13730896,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T16:31:14.597485",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}